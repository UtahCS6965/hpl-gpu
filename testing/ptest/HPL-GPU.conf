#############################################################################################################
#HPL-GPU 1.2 Runtime configuration file
#This file lists all mandatory options at the top, and optional tuning options in the end.
#The options in this file will override compile time settings.
#Refer to setup/Make.Generic.Options_StaticConfig for explanation how to set defaults at compile time.
#Possible options are (See below for the most relevant ones):
#HPL_PARAMDEFS, HPL_DISABLE_LOOKAHEAD, HPL_LOOKAHEAD2_TURNOFF, HPL_DURATION_FIND_HELPER,
#HPL_WARMUP, HPL_FASTRAND
#HPL_CALDGEMM_ASYNC_FACT_DGEMM, HPL_CALDGEMM_ASYNC_FACT_FIRST, HPL_CALDGEMM_ASYNC_DTRSM,
#HPL_CALDGEMM_ASYNC_FACT_DTRSM
#You can use the HPL_PARAMDEFS options multiple times to parameters one after another.
#############################################################################################################

#Custom CALDGEMM Parameters:
#HPL_PARAMDEFS: 

#In case the selected backend is OpenCL, this setting chooses the 3rd party library file that provides the OpenCL kernels.
HPL_PARAMDEFS: -Ol amddgemm.so

#This sets the GPU ratio, i.e. the fraction of the workload performed by the GPU. The following options exist: 1.0: All work performed by GPU, 0.0 <= GPURatio < 1.0: Fixed setting of
#GPU Ratio, -1.0: Fully automatic GPU Ratio calculation, -1.0 < GPURatio < 0.0: This defines the negative initial GPU Ratio: during runtime the ratio is then dynamically adapted. This
#means e.g. GPURatio = -0.9 will start with a ratio of 0.9, and then adapt it dynamically. The suggested settings are: 1.0 for GPU only and for efficiency optimized cases; In any other
#case a negative initial setting is suggested. Please see also the advence GPURatio options below.
HPL_PARAMDEFS: -j 1.0

#This defines the CPU core used for the management thread (-K) and for the broadcast thread (-Kb: -2 = MPI affinity). If unset this is autodetected.
HPL_PARAMDEFS: -K 0 -Kb -2

#Local matrix size for which alternate lookahead is activated. Usualy you want to leave this infinitely high. For optimized efficiency, always activate.
#For optimized performance, you can lower this setting in some cases. Optimal value must be tuned manually.
HPL_PARAMDEFS: -Ca 10000000

#Use the fast random number generator (faster initialization of the program, should be disabled for official runs)
#0: Disabled, 1: Only fast initialization (cannot verify), 2: Fast Initialization and Verification (defaul)
#HPL_FASTRAND: 2

#You can set several thresholds. If the remaining global matrix dimension is above the n-th threshold, the current NB for the next iteration is multiplied by the n-th multiplier
#HPL_NB_MULTIPLIER_THRESHOLD: 20000;10000
#HPL_NB_MULTIPLIER: 3;2

#############################################################################################################
#All the following are optional tuning options
#############################################################################################################

#HPL-GPU can pass the command line parameters of dgemm_bench to caldgemm, these parameters are evaluated last overwriting all other settings, in this example restricting CALDGEMM to 2 GPUs.
#HPL_PARAMDEFS: -Y 2

#You can reorder the GPU device numbering. In general, it is good to interleave NUMA nodes, i.e. if you have 2 NUMA nodes, 4 GPUs, GPUs 0 and 1 on node 0, GPUs 2 and 3 on node 1, the
#below setting is suggested. Keep in mind that the altered numbering affects other settings relative to GPU numbering, e.g. GPU_ALLOC_MAPPING
#HPL_PARAMDEFS: -/ 0;2;1;3

#Define CPU cores used to allocated GPU related memory. You should chose the correct NUMA nodes. For the above 4-GPU example and 2 10-core CPUs the following would be good:
#HPL_PARAMDEFS: -UA0 0 -UA1 10 -UA2 0 -UA3 10

#Exclude some CPU cores from CALDGEMM / HPL-GPU usage
#HPL_PARAMDEFS: -@ 8;9;18;19

#These option can define cutoff points (remaining local matrix size) where the Lookahead and Lookahead 2 features are turned off. (Needed for older AMD processors for better performance).
#HPL_DISABLE_LOOKAHEAD: 6000
#HPL_LOOKAHEAD2_TURNOFF: 4000

#Tool to find the duration of the core phase of HPL, needed to measure power consumption and power efficiency.
#HPL_DURATION_FIND_HELPER

#This defines the CPU core used for the device runtime. (-2 = same as main thread, -1 = all cores available, >= 0 = select core)
#HPL_PARAMDEFS: -tr -1

#In multi-node runs, the factorization causes significant CPU load on some but not all nodes. Caldgemm tries to take this into accound for automatic gpu ratio calculation, but sometimes this fails.
#In this case, the following setting can define a minimum GPU ratio (GPURatioDuringFact, -jf) in iterations where the node performs the factorization.
#See also -jm (GPURatioMax), -jt (GPURatioMarginTime), -js (GPURatioMarginTimeDuringFact), -jl (GPURatioLookaheadSizeMod), -jp (GPURatioPenalties), -jq (GPURatioPenaltyFactor).
#If you do not want them to interfere with ratio calculation, set them all to 0!
#HPL_PARAMDEFS: -jf 0.9

#Offload some steps during the factorization to the GPU. Offloading is active as soon as local matrix size is lower than the defined parameter.
#For best efficiency, you want to enable this always, i.e. set the parameter very high. For best performance, parameter must be tuned manually.
#HPL_CALDGEMM_ASYNC_FACT_DGEMM: 2000000
#HPL_CALDGEMM_ASYNC_FACT_FIRST
#HPL_PARAMDEFS: -Oa

#Same as above, but for the large Update-DTRSM (and DTRSM inside the factorization below). Optimal value for performance and efficiency is usually identical. Value must be tuned manually.
#HPL_CALDGEMM_ASYNC_DTRSM: 70000
#HPL_PARAMDEFS: -Od
#HPL_CALDGEMM_ASYNC_FACT_DTRSM: 0

#Preallocate some data to avoid unnecessary dynamic mallocs, define number of BBuffers to save memory. PreallocData should be larger than local matrix size / Nb. max_bbuffers should be larger than local matrix size / (Number of GPUs * Nb).
#HPL_PARAMDEFS: -Op 60 -bb 17

#Minimize the CPU workload, as soon as the local matrix size is below this threshold. Only applicable if GPURatio < 1.0. This can be used to help the GPU ratio estimation, and forces GPURatio to 1.0 for small matrices.
#HPL_PARAMDEFS: -Cm 2000000

#Enable (default) / disable HPL warmup iteration
#HPL_WARMUP
